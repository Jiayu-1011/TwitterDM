{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理情感词词典\n",
    "\n",
    "\n",
    "class SentiWordNet():\n",
    "    def __init__(self,netpath):\n",
    "        self.netpath = netpath\n",
    "        self.dictionary = {}\n",
    "    \n",
    "    def infoextract(self):\n",
    "        tempdict = {}\n",
    "        templist = []\n",
    "        try:\n",
    "            f = open(self.netpath,\"r\")\n",
    "        except IOError:\n",
    "            print(\"failed to open file!\")\n",
    "            exit()\n",
    "        print('start extracting.......')\n",
    "        \n",
    "    # Example line:\n",
    "    # POS     ID     PosS  NegS SynsetTerm#sensenumber Desc\n",
    "    # a   00009618  0.5    0.25  spartan#4 austere#3 ascetical#2  ……\n",
    "\n",
    "    \n",
    "        cnt = 0\n",
    "        for sor in tqdm(f.readlines()):\n",
    "            cnt += 1\n",
    "#             if(cnt%1000==0):\n",
    "#                 print(cnt*100/117687, '%')\n",
    "            if sor.strip().startswith(\"#\"):\n",
    "                pass\n",
    "            else:\n",
    "                data = sor.split(\"\\t\")\n",
    "                if len(data) != 6:\n",
    "                    print('invalid data')\n",
    "                    break\n",
    "                    \n",
    "                wordTypeMarker = data[0]      \n",
    "                synsetScore = float(data[2]) - float(data[3])   #// Calculate synset score as score = PosS - NegS\n",
    "                synTermsSplit = data[4].split(\" \")    # word#sentimentscore\n",
    "                \n",
    "                for w in synTermsSplit:\n",
    "                    synTermAndRank = w.split(\"#\")           #\n",
    "                    synTerm = synTermAndRank[0] + \"#\" + wordTypeMarker    #单词#词性\n",
    "                    synTermRank = int(synTermAndRank[1])    \n",
    "                    if  synTerm in tempdict:\n",
    "                        t = [synTermRank,synsetScore]\n",
    "                        tempdict.get(synTerm).append(t)            \n",
    "                    else:\n",
    "                        temp = {synTerm:[]}\n",
    "                        t = [synTermRank,synsetScore]\n",
    "                        temp.get(synTerm).append(t)\n",
    "                        tempdict.update(temp) \n",
    "#                         print(tempdict)\n",
    "\n",
    "                for key in tempdict.keys():\n",
    "                    score = 0.0\n",
    "                    ssum = 0.0            \n",
    "                    for wordlist in tempdict.get(key):\n",
    "#                         print(wordlist)\n",
    "                        score += wordlist[1]/wordlist[0]\n",
    "                        ssum += 1.0/wordlist[0]\n",
    "                        score /= ssum\n",
    "                        self.dictionary.update({key:score})\n",
    "    \n",
    "    def getscore(self,word,pos):\n",
    "        return self.dictionary.get(word + \"#\" + pos)\n",
    "             \n",
    "            \n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.chdir(os.getcwd())\n",
    "    if os.path.exists('./dictionaries/sentiment_dictionary/SentiWordNet3.0.0.csv'):\n",
    "        swn_data = pd.read_csv('./dictionaries/sentiment_dictionary/SentiWordNet3.0.0.csv')\n",
    "        swn_data.head()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        netpath = r'./dictionaries/sentiment_dictionary/SentiWordNet_3.0.0.txt'\n",
    "        swn= SentiWordNet(netpath)\n",
    "        swn.infoextract()\n",
    "        \n",
    "        word = []\n",
    "        attr = []\n",
    "        score = []\n",
    "        for key in swn.dictionary:\n",
    "            word.append(key.split('#')[0])\n",
    "            attr.append(key.split('#')[1])\n",
    "            score.append(swn.dictionary[key])\n",
    "\n",
    "        dataframe = pd.DataFrame({'sentiment_word':word, 'attr':attr, 'score':score})\n",
    "        dataframe.to_csv(\"./dictionaries/sentiment_dictionary/SentiWordNet_3.0.0.csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理程度副词词典\n",
    "def get_degree_dictionary(path):\n",
    "    \n",
    "    groups = ['1', '2', '3', '4', '5']\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        words = []\n",
    "        weights = []\n",
    "        weight = 1\n",
    "        for line in f.readlines():\n",
    "            if line[0] == '#' or line.strip() == '':\n",
    "                continue\n",
    "#             print(line[0])\n",
    "            \n",
    "            if line[0] in groups:\n",
    "#                 print(line[0])\n",
    "                weight = 2 - (int(line[0])-1)*0.3\n",
    "                continue\n",
    "            \n",
    "            words.append(line.strip('\\n'))\n",
    "            weights.append(weight)\n",
    "        \n",
    "    degree_pd = pd.DataFrame({'word': words, 'weight': weights})\n",
    "    \n",
    "    print(degree_pd)\n",
    "    \n",
    "    degree_pd.to_csv('./dictionaries/degree_dictionary/degree_dictionary.csv',\n",
    "                     index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word  weight\n",
      "0         absolute     2.0\n",
      "1       absolutely     2.0\n",
      "2       alarmingly     2.0\n",
      "3        amazingly     2.0\n",
      "4    astonishingly     2.0\n",
      "..             ...     ...\n",
      "103          light     0.8\n",
      "104         merely     0.8\n",
      "105       relative     0.8\n",
      "106         slight     0.8\n",
      "107       slightly     0.8\n",
      "\n",
      "[108 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "get_degree_dictionary(path='./dictionaries/degree_dictionary/degree_dictionary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_dictionary(path):\n",
    "    negative_pd = pd.DataFrame()\n",
    "    words = []\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            words.append(line.strip('\\n'))\n",
    "    \n",
    "    negative_pd['word'] = words\n",
    "    \n",
    "    negative_pd.to_csv('./dictionaries/negative_dictionary/negative_dictionary.csv',index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_negative_dictionary(path='./dictionaries/negative_dictionary/negative_dictionary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
